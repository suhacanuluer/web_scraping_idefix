{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f010ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from vnlp import SentimentAnalyzer\n",
    "from vnlp import StemmerAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from snowballstemmer import TurkishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_all_data():\n",
    "    page_number = 1;\n",
    "    finish_page = 1;\n",
    "    dataset = list()\n",
    "\n",
    "    while page_number <= finish_page:\n",
    "        books_url = \"https://www.idefix.com/kategori/Kitap/Edebiyat/grupno=00055?ShowNotForSale=True&Page=\"+ str(page_number) + \"\"\n",
    "        books_request = requests.get(books_url)\n",
    "        books_html = BeautifulSoup(books_request.content,\"lxml\")\n",
    "\n",
    "        books_div1 = books_html.find(\"div\",attrs={\"class\":\"no-margin productListNewBox boxes books clearfix\"})\n",
    "        books_div2 = books_div1.find(\"div\",attrs={\"class\":\"row\"})\n",
    "        books_list = books_div2.find_all(\"div\",attrs={\"class\":\"cart-product-box-view\"})\n",
    "\n",
    "        for book_html in books_list:\n",
    "            book_link = \"https://www.idefix.com/\"+book_html.a.get(\"href\")\n",
    "            books_request = requests.get(book_link)\n",
    "\n",
    "            book_page_html = BeautifulSoup(books_request.content,\"lxml\")\n",
    "            comments_html = book_page_html.find_all(\"div\",attrs={\"class\":\"comment\"})\n",
    "\n",
    "            book_div1 = book_page_html.find(\"div\",attrs={\"class\":\"product-info hidden-lg hidden-md hidden-sm col-xs-12\"})\n",
    "            if(book_div1 is None):  # if the link of the book is not available, go to the next book.\n",
    "                continue\n",
    "            book_name = book_div1.find(\"h3\",attrs={\"style\":\"margin-bottom: 10px !important; margin-top: 0px;\"}).get_text().replace('\\n',\"\").replace(' ',\"\")\n",
    "\n",
    "            if (len(comments_html) != 0):\n",
    "                for comment_html in comments_html:\n",
    "                    comment = comment_html.find(id=\"reviewBody\").get_text()\n",
    "                    data = [comment, 0]\n",
    "                    dataset.append(data)\n",
    "        page_number += 1\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ddc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_excel(file_name, data):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    i = 1\n",
    "    for comment in data:\n",
    "        ws[\"A\" + str(i)] = comment[0]\n",
    "        ws[\"B\" + str(i)] = comment[1]\n",
    "        i += 1\n",
    "    wb.save(file_name + \".xlsx\")\n",
    "\n",
    "def read_excel(file_name):\n",
    "    wb = load_workbook(filename = (file_name + \".xlsx\"))\n",
    "    sheet_ranges = wb[\"Sheet\"]\n",
    "    data = list()\n",
    "    for i in range(1, sheet_ranges.max_row + 1):\n",
    "        data.append([sheet_ranges[\"A\" + str(i)].value, sheet_ranges[\"B\" + str(i)].value])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518343c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "def analyzer(data):\n",
    "    analyzed_data = list()\n",
    "    for comment in data:\n",
    "        score = sentiment_analyzer.predict_proba(comment[0])\n",
    "        analyzed_data.append([comment[0], score * 5])\n",
    "    return analyzed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61da8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctation = string.punctuation\n",
    "punctuation ='''!()-[]{};':'\"\\,<>./?@#$%^&*_~'''\n",
    "#Özel karakterleri temizleme\n",
    "def special_character_remover(comment):\n",
    "    return comment.translate(str.maketrans(\"\",\"\",punctuation))\n",
    "\n",
    "#Stopword cleaning\n",
    "stopword = set(stopwords.words(\"turkish\"))\n",
    "def stopwords_remover(comment):\n",
    "    return \" \".join([word for word in str(comment).split() if word not in stopword])\n",
    "\n",
    "count = Counter()\n",
    "#sık kullanılan kelimeleri temizleme\n",
    "def frequently_words_remover(comment):\n",
    "    for word in comment.split():\n",
    "        count[word] += 1\n",
    "    frequency = set([i for (i,j) in count.most_common(15)])\n",
    "    return frequency\n",
    "\n",
    "def frequency_remover(comment):\n",
    "    return \" \".join([word for word in str(comment).split() if word not in frequently_words_remover(comment)])\n",
    "\n",
    "#Emojileri Silme\n",
    "def emoji_remover(comment):\n",
    "    emoji = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  \n",
    "                               u\"\\U0001F300-\\U0001F5FF\"                                 \n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                               u\"\\U00002500-\\U00002BEF\"                                 \n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  \n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji.sub(r\"\",comment)\n",
    "\n",
    "#----------------Kelime Kökünü Alma\n",
    "stemmer = StemmerAnalyzer()\n",
    "def get_root_word(comment):\n",
    "    root_words = \"\"\n",
    "    wordlist = stemmer.predict(comment)\n",
    "    for sentence in wordlist:\n",
    "        root_words += sentence.split(\"+\")[0] + \" \"\n",
    "    return root_words\n",
    "    \n",
    "# normalization cleaning\n",
    "def normalization(data):\n",
    "    dummy_data = data\n",
    "    for comment in dummy_data:\n",
    "        comment[0] = get_root_word(stopwords_remover(special_character_remover((emoji_remover(comment[0])))))\n",
    "    return dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d38ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_comments = take_all_data()\n",
    "write_excel(\"original_comments\", original_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ebf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_comments = normalization(read_excel(\"original_comments\"))\n",
    "write_excel(\"normalized_comments\", normalized_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc7f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_original_comments = analyzer(read_excel(\"original_comments\"))\n",
    "write_excel(\"analyzed_original_comments\", analyzed_original_comments) \n",
    "\n",
    "analyzed_normalized_comments = analyzer(read_excel(\"normalized_comments\"))\n",
    "write_excel(\"analyzed_normalized_comments\", analyzed_normalized_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_without_stopwords = normalization(original_comments)\n",
    "for i in normalized_comments:\n",
    "    print(i[0])\n",
    "# print(comments_without_stopwords[i][0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
